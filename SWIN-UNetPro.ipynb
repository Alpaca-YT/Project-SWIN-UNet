{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0088452d-3660-462d-bdaf-7e6eaeff02bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alpaca_YT\\anaconda3\\envs\\mphy0041-cw2-pt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始在 cuda 上训练最终修正版的 SwinUnet (使用高频加权损失)...\n",
      "Epoch 01/15 | Train Loss: 0.043088 | Val Loss: 0.016183\n",
      "Epoch 02/15 | Train Loss: 0.017271 | Val Loss: 0.015490\n",
      "Epoch 03/15 | Train Loss: 0.016100 | Val Loss: 0.015278\n",
      "Epoch 04/15 | Train Loss: 0.015806 | Val Loss: 0.015056\n",
      "Epoch 05/15 | Train Loss: 0.015515 | Val Loss: 0.014686\n",
      "Epoch 06/15 | Train Loss: 0.015235 | Val Loss: 0.014705\n",
      "Epoch 07/15 | Train Loss: 0.014983 | Val Loss: 0.014519\n",
      "Epoch 08/15 | Train Loss: 0.015414 | Val Loss: 1.025264\n",
      "Epoch 09/15 | Train Loss: 0.015566 | Val Loss: 0.015961\n",
      "Epoch 10/15 | Train Loss: 0.014998 | Val Loss: 0.014283\n",
      "Epoch 11/15 | Train Loss: 0.014723 | Val Loss: 0.014255\n",
      "Epoch 12/15 | Train Loss: 0.014464 | Val Loss: 0.014044\n",
      "Epoch 13/15 | Train Loss: 0.014326 | Val Loss: 0.014039\n",
      "Epoch 14/15 | Train Loss: 0.014220 | Val Loss: 0.013894\n",
      "Epoch 15/15 | Train Loss: 0.014130 | Val Loss: 0.013827\n",
      "\n",
      "训练完毕，所有模型已保存在 'Train_SwinUnet_Pro/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. 设置和数据加载部分 (保持不变)\n",
    "# ----------------------------------------\n",
    "# (此处省略与上次相同的 Dataset 定义和数据加载代码，以保持简洁)\n",
    "patches_folder = r\"C:\\Users\\Alpaca_YT\\pythonSet\\lung_slices_dataset\\lung_slice_xy\"\n",
    "output_model_dir = \"Train_SwinUnet_Pro\" # 使用新的文件夹以避免混淆\n",
    "os.makedirs(output_model_dir, exist_ok=True)\n",
    "num_epochs = 15\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "\n",
    "all_fns = sorted([f for f in os.listdir(patches_folder) if f.lower().endswith(\".jpg\")])\n",
    "all_indices = list(range(len(all_fns)))\n",
    "train_idxs, val_idxs = train_test_split(all_indices, test_size=0.25, random_state=42)\n",
    "\n",
    "class RotLowHighDataset(Dataset):\n",
    "    def __init__(self, patches_folder, indices, all_fns_list, transform=None):\n",
    "        super().__init__()\n",
    "        self.patches_folder = patches_folder\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "        self.fns = [all_fns_list[i] for i in indices]\n",
    "    def __len__(self): return len(self.fns) * 2\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx, rot_flag = idx // 2, idx % 2\n",
    "        fn = self.fns[img_idx]\n",
    "        img_path = os.path.join(self.patches_folder, fn)\n",
    "        arr = np.array(Image.open(img_path).convert(\"L\"))\n",
    "        if rot_flag == 1: arr = np.rot90(arr, k=1)\n",
    "        down_arr = cv2.resize(arr, (256, 32), interpolation=cv2.INTER_AREA)\n",
    "        up_img = cv2.resize(down_arr, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        inp_t = self.transform(Image.fromarray(up_img))\n",
    "        tgt_t = self.transform(Image.fromarray(arr))\n",
    "        return inp_t, tgt_t\n",
    "\n",
    "class PlainLowHighDataset(Dataset):\n",
    "    def __init__(self, patches_folder, indices, all_fns_list, transform=None):\n",
    "        super().__init__()\n",
    "        self.patches_folder = patches_folder\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "        self.fns = [all_fns_list[i] for i in indices]\n",
    "    def __len__(self): return len(self.fns)\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        img_path = os.path.join(self.patches_folder, fn)\n",
    "        arr = np.array(Image.open(img_path).convert(\"L\"))\n",
    "        down_arr = cv2.resize(arr, (256, 32), interpolation=cv2.INTER_AREA)\n",
    "        up_img = cv2.resize(down_arr, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        inp_t = self.transform(Image.fromarray(up_img))\n",
    "        tgt_t = self.transform(Image.fromarray(arr))\n",
    "        return inp_t, tgt_t\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. 定义修正后的 SwinUnet 模型\n",
    "# ----------------------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, 1, 1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, 1, 1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UpBlockPixelShuffle(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch * 4, 3, 1, 1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x): return self.relu(self.pixel_shuffle(self.conv(x)))\n",
    "\n",
    "class SwinUnet(nn.Module):\n",
    "    def __init__(self, in_ch: int = 1, out_ch: int = 1, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            'swin_base_patch4_window7_224',\n",
    "            pretrained=pretrained,\n",
    "            features_only=True,\n",
    "            in_chans=3,\n",
    "            img_size=256\n",
    "        )\n",
    "\n",
    "        encoder_channels: List[int] = self.encoder.feature_info.channels()\n",
    "        # Swin-Base的通道数通常为: [128, 256, 512, 1024]\n",
    "\n",
    "        # --- 新增全局特征提取模块 ---\n",
    "        # 放在Swin编码器最深层特征 (e4, 通道数 encoder_channels[3]) 之后\n",
    "        # 我们可以用一个 DoubleConv 来进一步处理这些最高级特征\n",
    "        self.global_feature_extractor = DoubleConv(encoder_channels[3], encoder_channels[3])\n",
    "        # 如果觉得 DoubleConv 的感受野不够，可以堆叠更多层或使用更大的kernel_size，或者 Dilated Conv\n",
    "\n",
    "        # 解码器部分保持与之前匹配Swin-Base通道数一致\n",
    "        self.up4 = UpBlockPixelShuffle(encoder_channels[3], 512)\n",
    "        self.dec4 = DoubleConv(encoder_channels[2] + 512, 512)\n",
    "\n",
    "        self.up3 = UpBlockPixelShuffle(512, 256)\n",
    "        self.dec3 = DoubleConv(encoder_channels[1] + 256, 256)\n",
    "\n",
    "        self.up2 = UpBlockPixelShuffle(256, 128)\n",
    "        self.dec2 = DoubleConv(encoder_channels[0] + 128, 128)\n",
    "\n",
    "        self.up1 = UpBlockPixelShuffle(128, 64)\n",
    "        self.dec1 = DoubleConv(in_ch + 64, 64)\n",
    "\n",
    "        self.outc = nn.Conv2d(64, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_orig = x\n",
    "        if self.in_ch == 1 and x.size(1) == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "\n",
    "        features = self.encoder(x)\n",
    "        e1 = features[0].permute(0, 3, 1, 2)\n",
    "        e2 = features[1].permute(0, 3, 1, 2)\n",
    "        e3 = features[2].permute(0, 3, 1, 2)\n",
    "        e4 = features[3].permute(0, 3, 1, 2) # 最深层特征，最低分辨率\n",
    "\n",
    "        # --- 应用新增的全局特征提取模块 ---\n",
    "        e4_processed = self.global_feature_extractor(e4) # 对最深层特征进行额外处理\n",
    "\n",
    "        # 解码器路径\n",
    "        u4 = self.up4(e4_processed) # 解码器从处理后的 e4_processed 开始\n",
    "        d4 = self.dec4(torch.cat([u4, e3], dim=1))\n",
    "\n",
    "        u3 = self.up3(d4)\n",
    "        d3 = self.dec3(torch.cat([u3, e2], dim=1))\n",
    "\n",
    "        u2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([u2, e1], dim=1))\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        \n",
    "        final_up = F.interpolate(u1, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        d1 = self.dec1(torch.cat([final_up, x_orig], dim=1))\n",
    "        \n",
    "        return self.outc(d1)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3. 准备训练 (保持不变)\n",
    "# ----------------------------------------\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = RotLowHighDataset(patches_folder, train_idxs, all_fns, transform)\n",
    "val_dataset = PlainLowHighDataset(patches_folder, val_idxs, all_fns, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SwinUnet(in_ch=1, out_ch=1, pretrained=True).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4. 训练循环 (保持不变)\n",
    "# ----------------------------------------\n",
    "# ----------------------------------------\n",
    "# 准备 Dataloader, 模型, 优化器 (保持不变)\n",
    "# ----------------------------------------\n",
    "\n",
    "# criterion 仍然是基础的MSE损失\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# ### 修改点 1：定义高频损失所需组件 ###\n",
    "# 定义拉普拉斯卷积核，并将其发送到正确的设备\n",
    "laplacian_kernel = torch.tensor(\n",
    "    [[0.0, -1.0, 0.0],\n",
    "     [-1.0, 4.0, -1.0],\n",
    "     [0.0, -1.0, 0.0]],\n",
    "    device=device, dtype=torch.float32\n",
    ").view(1, 1, 3, 3)\n",
    "\n",
    "# 定义高频损失的权重\n",
    "lambda_hf = 0.5\n",
    "\n",
    "# 定义高频损失函数\n",
    "def high_freq_loss(pred, target):\n",
    "    \"\"\"计算预测和目标之间高频分量的MSE损失\"\"\"\n",
    "    pred_lap = F.conv2d(pred, laplacian_kernel, padding=1)\n",
    "    tgt_lap  = F.conv2d(target, laplacian_kernel, padding=1)\n",
    "    return F.mse_loss(pred_lap, tgt_lap)\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 训练循环 (修改损失计算部分)\n",
    "# ----------------------------------------\n",
    "print(f\"开始在 {device} 上训练最终修正版的 SwinUnet (使用高频加权损失)...\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inp, tgt in train_loader:\n",
    "        inp, tgt = inp.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(inp)\n",
    "        \n",
    "        # ### 修改点 2：计算复合损失 ###\n",
    "        mse_train = criterion(out, tgt)\n",
    "        hf_train = high_freq_loss(out, tgt)\n",
    "        loss = mse_train + lambda_hf * hf_train # 总损失 = MSE + λ * 高频损失\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inp.size(0)\n",
    "    avg_train_loss = train_loss / len(train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inp_v, tgt_v in val_loader:\n",
    "            inp_v, tgt_v = inp_v.to(device), tgt_v.to(device)\n",
    "            out_v = model(inp_v)\n",
    "            \n",
    "            # ### 修改点 3：在验证时也使用相同的复合损失 ###\n",
    "            mse_val = criterion(out_v, tgt_v)\n",
    "            hf_val = high_freq_loss(out_v, tgt_v)\n",
    "            loss_v = mse_val + lambda_hf * hf_val\n",
    "\n",
    "            val_loss += loss_v.item() * inp_v.size(0)\n",
    "    avg_val_loss = val_loss / len(val_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/{num_epochs} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "    # 保存模型权重时，可以加上标识，例如 \"hf\" 代表 high-frequency\n",
    "    ckpt_path = os.path.join(output_model_dir, f\"SwinUnet_Pro_hf_epoch{epoch:02d}.pth\")\n",
    "    torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "print(f\"\\n训练完毕，所有模型已保存在 '{output_model_dir}/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1e98f6-c33c-437b-9cd3-340148cc1471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alpaca_YT\\AppData\\Local\\Temp\\ipykernel_10556\\1968020345.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载模型权重: Train_SwinUnet_Pro/SwinUnet_Pro_hf_epoch15.pth\n",
      "\n",
      "在 cuda 上评估模型...\n",
      "\n",
      "-> 验证集结果:\n",
      "   - 平均 PSNR: 24.6768 dB\n",
      "   - 平均 SSIM: 0.6245\n",
      "\n",
      "-> 测试集结果:\n",
      "   - 平均 PSNR: 24.1866 dB\n",
      "   - 平均 SSIM: 0.5935\n",
      "\n",
      "已保存 5 组测试图像到 'lung_SwinNetPro_reconstructions/' 文件夹中供查看。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr_metric\n",
    "from skimage.metrics import structural_similarity as ssim_metric\n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. 定义与训练时完全一致的模型和 Dataset 类\n",
    "# ----------------------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UpBlockPixelShuffle(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch * 4, 3, 1, 1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x): return self.relu(self.pixel_shuffle(self.conv(x)))\n",
    "\n",
    "class SwinUnet(nn.Module):\n",
    "    def __init__(self, in_ch: int = 1, out_ch: int = 1, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            'swin_base_patch4_window7_224',\n",
    "            pretrained=pretrained,\n",
    "            features_only=True,\n",
    "            in_chans=3,\n",
    "            img_size=256\n",
    "        )\n",
    "\n",
    "        encoder_channels: List[int] = self.encoder.feature_info.channels()\n",
    "        # Swin-Base的通道数通常为: [128, 256, 512, 1024]\n",
    "\n",
    "        # --- 新增全局特征提取模块 ---\n",
    "        # 放在Swin编码器最深层特征 (e4, 通道数 encoder_channels[3]) 之后\n",
    "        # 我们可以用一个 DoubleConv 来进一步处理这些最高级特征\n",
    "        self.global_feature_extractor = DoubleConv(encoder_channels[3], encoder_channels[3])\n",
    "        # 如果觉得 DoubleConv 的感受野不够，可以堆叠更多层或使用更大的kernel_size，或者 Dilated Conv\n",
    "\n",
    "        # 解码器部分保持与之前匹配Swin-Base通道数一致\n",
    "        self.up4 = UpBlockPixelShuffle(encoder_channels[3], 512)\n",
    "        self.dec4 = DoubleConv(encoder_channels[2] + 512, 512)\n",
    "\n",
    "        self.up3 = UpBlockPixelShuffle(512, 256)\n",
    "        self.dec3 = DoubleConv(encoder_channels[1] + 256, 256)\n",
    "\n",
    "        self.up2 = UpBlockPixelShuffle(256, 128)\n",
    "        self.dec2 = DoubleConv(encoder_channels[0] + 128, 128)\n",
    "\n",
    "        self.up1 = UpBlockPixelShuffle(128, 64)\n",
    "        self.dec1 = DoubleConv(in_ch + 64, 64)\n",
    "\n",
    "        self.outc = nn.Conv2d(64, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_orig = x\n",
    "        if self.in_ch == 1 and x.size(1) == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "\n",
    "        features = self.encoder(x)\n",
    "        e1 = features[0].permute(0, 3, 1, 2)\n",
    "        e2 = features[1].permute(0, 3, 1, 2)\n",
    "        e3 = features[2].permute(0, 3, 1, 2)\n",
    "        e4 = features[3].permute(0, 3, 1, 2) # 最深层特征，最低分辨率\n",
    "\n",
    "        # --- 应用新增的全局特征提取模块 ---\n",
    "        e4_processed = self.global_feature_extractor(e4) # 对最深层特征进行额外处理\n",
    "\n",
    "        # 解码器路径\n",
    "        u4 = self.up4(e4_processed) # 解码器从处理后的 e4_processed 开始\n",
    "        d4 = self.dec4(torch.cat([u4, e3], dim=1))\n",
    "\n",
    "        u3 = self.up3(d4)\n",
    "        d3 = self.dec3(torch.cat([u3, e2], dim=1))\n",
    "\n",
    "        u2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([u2, e1], dim=1))\n",
    "\n",
    "        u1 = self.up1(d2)\n",
    "        \n",
    "        final_up = F.interpolate(u1, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        d1 = self.dec1(torch.cat([final_up, x_orig], dim=1))\n",
    "        \n",
    "        return self.outc(d1)\n",
    "\n",
    "\n",
    "# ### 修改点 1：让 Dataset 返回文件名 ###\n",
    "class PlainLowHighDataset(Dataset):\n",
    "    def __init__(self, patches_folder, indices, all_fns_list, transform=None):\n",
    "        super().__init__()\n",
    "        self.patches_folder, self.transform = patches_folder, transform or transforms.ToTensor()\n",
    "        self.fns = [all_fns_list[i] for i in indices]\n",
    "    def __len__(self): return len(self.fns)\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.fns[idx]\n",
    "        img_path = os.path.join(self.patches_folder, fn)\n",
    "        arr = np.array(Image.open(img_path).convert(\"L\"))\n",
    "        down_arr = cv2.resize(arr, (256, 32), interpolation=cv2.INTER_AREA)\n",
    "        up_img = cv2.resize(down_arr, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        inp_t = self.transform(Image.fromarray(up_img))\n",
    "        tgt_t = self.transform(Image.fromarray(arr))\n",
    "        return inp_t, tgt_t, fn # 返回文件名\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. 设置路径和参数\n",
    "# ----------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.ToTensor()\n",
    "# ### 新增：定义保存图像的文件夹和数量 ###\n",
    "RECONSTRUCTION_DIR = \"lung_SwinNetPro_reconstructions\"\n",
    "IMAGES_TO_SAVE = 5\n",
    "os.makedirs(RECONSTRUCTION_DIR, exist_ok=True)\n",
    "\n",
    "# 准备 Dataloaders (与之前相同)\n",
    "val_patches_folder = r\"C:\\Users\\Alpaca_YT\\pythonSet\\lung_slices_dataset\\lung_slice_xy\"\n",
    "all_val_fns = sorted([f for f in os.listdir(val_patches_folder) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "all_val_indices = list(range(len(all_val_fns)))\n",
    "_, val_idxs = train_test_split(all_val_indices, test_size=0.25, random_state=42)\n",
    "val_dataset = PlainLowHighDataset(val_patches_folder, val_idxs, all_val_fns, transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_patches_folder = r\"C:\\Users\\Alpaca_YT\\pythonSet\\lung_slices_dataset\\lung_slice_yz\"\n",
    "all_test_fns = sorted([f for f in os.listdir(test_patches_folder) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "all_test_indices = list(range(len(all_test_fns)))\n",
    "test_dataset = PlainLowHighDataset(test_patches_folder, all_test_indices, all_test_fns, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3. 加载模型权重 (与之前相同)\n",
    "# ----------------------------------------\n",
    "model = SwinUnet(in_ch=1, out_ch=1, pretrained=False).to(device)\n",
    "checkpoint_path = r\"Train_SwinUnet_Pro/SwinUnet_Pro_hf_epoch15.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()\n",
    "print(f\"成功加载模型权重: {checkpoint_path}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4. 定义评估函数 (增加保存逻辑)\n",
    "# ----------------------------------------\n",
    "def tensor_to_image(tensor):\n",
    "    \"\"\"将 [0,1] 范围的Tensor转换为可保存的PIL Image对象\"\"\"\n",
    "    arr = tensor.clamp(0, 1).cpu().squeeze().numpy()\n",
    "    return Image.fromarray((arr * 255).round().astype(np.uint8))\n",
    "\n",
    "# ### 修改点 2：为函数增加保存功能相关的参数 ###\n",
    "def evaluate_model(loader, model_to_test, output_dir=None, save_count=0):\n",
    "    total_psnr, total_ssim, count = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        # ### 修改点 3：使用 enumerate 以获取索引 ###\n",
    "        for i, (inp_t, tgt_t, fn) in enumerate(loader):\n",
    "            # 解包文件名元组（如果dataloader返回的是元组）\n",
    "            fn = fn[0] if isinstance(fn, (list, tuple)) else fn\n",
    "\n",
    "            inp_t, tgt_t = inp_t.to(device), tgt_t.to(device)\n",
    "            out_t = model_to_test(inp_t)\n",
    "            \n",
    "            pred_np = out_t.clamp(0, 1).cpu().squeeze().numpy()\n",
    "            target_np = tgt_t.cpu().squeeze().numpy()\n",
    "            \n",
    "            total_psnr += psnr_metric(target_np, pred_np, data_range=1.0)\n",
    "            total_ssim += ssim_metric(target_np, pred_np, data_range=1.0, channel_axis=None)\n",
    "            count += 1\n",
    "            \n",
    "            # ### 修改点 4：保存指定数量的图像 ###\n",
    "            if output_dir is not None and i < save_count:\n",
    "                base_name = os.path.splitext(fn)[0]\n",
    "                # 保存三种图像以供对比\n",
    "                tensor_to_image(inp_t).save(os.path.join(output_dir, f\"{base_name}_01_input.png\"))\n",
    "                tensor_to_image(out_t).save(os.path.join(output_dir, f\"{base_name}_02_reconstructed.png\"))\n",
    "                tensor_to_image(tgt_t).save(os.path.join(output_dir, f\"{base_name}_03_ground_truth.png\"))\n",
    "\n",
    "    return total_psnr / count, total_ssim / count\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5. 执行评估并打印结果\n",
    "# ----------------------------------------\n",
    "print(f\"\\n在 {device} 上评估模型...\")\n",
    "\n",
    "# 评估验证集，不保存图像\n",
    "val_psnr, val_ssim = evaluate_model(val_loader, model)\n",
    "print(f\"\\n-> 验证集结果:\")\n",
    "print(f\"   - 平均 PSNR: {val_psnr:.4f} dB\")\n",
    "print(f\"   - 平均 SSIM: {val_ssim:.4f}\")\n",
    "\n",
    "# ### 修改点 5：评估测试集，并传入保存图像的参数 ###\n",
    "test_psnr, test_ssim = evaluate_model(test_loader, model, output_dir=RECONSTRUCTION_DIR, save_count=IMAGES_TO_SAVE)\n",
    "print(f\"\\n-> 测试集结果:\")\n",
    "print(f\"   - 平均 PSNR: {test_psnr:.4f} dB\")\n",
    "print(f\"   - 平均 SSIM: {test_ssim:.4f}\")\n",
    "print(f\"\\n已保存 {IMAGES_TO_SAVE} 组测试图像到 '{RECONSTRUCTION_DIR}/' 文件夹中供查看。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c5d8f-0dee-441b-91c3-2127969979c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
